# ============================================
# API KEYS
# ============================================
OPENAI_API_KEY=sk-your-api-key-here  # Get from https://platform.openai.com/api-keys

# ============================================
# LLM CONFIGURATION (for RAG generation)
# ============================================
LLM_PROVIDER=openai          # Options: "openai" or "vllm"
MODEL=gpt-4o-mini            # OpenAI model to use

# vLLM Configuration (Optional - only needed if LLM_PROVIDER=vllm)
# VLLM_BASE_URL=http://localhost:8000
# VLLM_MODEL=meta-llama/Meta-Llama-3-8B-Instruct
# VLLM_API_KEY=sk-local

# ============================================
# EMBEDDING CONFIGURATION (for document ingestion)
# ============================================
EMBEDDING_PROVIDER=openai    # Options: "local" or "openai"

# OpenAI Embeddings (when EMBEDDING_PROVIDER=openai)
OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# Local Embeddings (when EMBEDDING_PROVIDER=local)
# LOCAL_EMBEDDING_MODEL=BAAI/bge-base-en-v1.5
# LOCAL_MODELS_CACHE_DIR=./models

# ============================================
# CHUNKING CONFIGURATION
# ============================================
CHUNKING_METHOD=token        # Options: "token" or "char"
CHUNK_SIZE=450               # Number of tokens (for token method) or chars (for char method)
CHUNK_OVERLAP=90             # Overlap size (recommended: 20% of CHUNK_SIZE)
